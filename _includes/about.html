<section id="about" class="container-outer dark fit-page">
  <div class="container">
    <span class="main-text">
      Edge Benchmark measures speed of your Machine Learning models on a wide variety of real devices.
    </span>

    <hr class="divider light">

    <span class="long-text">
      We all know it. We are in the middle of developing a Machine Learning model for edge device and we need to know how fast would the model be if run on <strong>real device</strong>. But in order to measure the speed, we have to convert our model to special mobile model format, connect testing device with the right prebuilt inference engine on it, upload the model through <i>adb</i>, run benchmark and then try to figure out how fast the model is or where the potential bottleneck might be hidden, all only from the cryptic output of benchmark in terminal.
      <br>
      <br>
      <strong>Wouldn't be nice if this process of model benchmarking is easier?</strong>
      <br>
    </span>

  </div>
</section>
